% This is part of the Avaneya Project Crew Handbook.
% Copyright (C) 2010-2018 Cartesian Theatre™ <info@cartesiantheatre.com>.
% See the file Copying for details on copying conditions.

% Algorithms, Optimizations, & Tips section...
\StartSection{Algorithms, Optimizations, & Tips}
\placefigure
    [right, 0*hang]
    [figure:Kip_Pad]
    {Good code comes from a healthy environment.}
    {\externalfigure[Engineer_Contributors/Images/Kip_Pad.png][][width=.55\textwidth]}

In this section we will share some of the different algorithms, optimizations, and tips that are useful in tackling the many different problems we must address. Consider the following advice tentative and hardly sacrosanct. This is because no one knows with certainty what the future holds. We may find down the road that any of the following approaches are problematic, encouraging a need to explore alternatives. This is why {\it re}--search is called what it is.

With every bit of eye candy or bell and whistle we add there comes the problem of an increased burden on player's hardware. We need to take advantage of optimizations whenever possible. 

As a general rule, asymptotic complexity (how an algorithm scales) is much more important than constant time optimizations. But assessing an algorithm's complexity can be complicated. Fortunately you do not need a degree from a computer science department to understand the idea.\footnotecite[asymptotic_notation] It is a very practical tool that is there to help you and need not be an esoteric black art.

Still, sometimes having improved an algorithm from quadratic to linear logarithmic performance, a useful constant time optimization is all that remains if you want to go further. Most libraries the AresEngine (\in{section}[AresEngine's Architecture]) links against like SDL and Ogre3D are already heavily optimized. But of course not necessarily everything a game engine consists of, as well as the scripts that drive it, are found in 3\high{rd} party libraries. If that were the case we would not have to write anything.

\StartSubSection{Fallback Shaders}
Those who work in the non--free software industry sometimes over inflate their target user's hardware requirements. The corporations they work for are unconcerned with leveraging the most out of what users already have. They profit, at least in part, when users are perpetually convinced their hardware is inadequate, coercing them into undue, mindless, and wasteful consumption that only adds to the volume of the mountains of garbage we already have.\footnotecite[caroll2008] 

As an example the US government is one of the largest producers of electronic garbage in the world. It throws out over 10,000 computers every week.\footnotecite[urbina2013] That is not to say that users should never upgrade, but only so long as it is actually rational to do so and not merely for the sake of some special interest group trying to sell us a new video card.
\placefigure
    [right, 3*hang]
    [figure:Fluid_Dynamics]
    {Our early fluid dynamics simulator generated entirely on the GPU.}
    {\externalfigure[Engineer_Contributors/Images/Fluid_Dynamics.png][][width=.35\textwidth]}

We rely on visual effects like any game to make it interesting. Consider some creative examples. The scanline effect of a fictional terminal's interface; gas sublimation of exposed Martian ice and the ensuing dust devils; a solar lens flare; atmospheric \chemical{CO_2} clouds visible in the day sky, or glowing meteorites and auroras at night; a construction site's flood lights and the welder's sparks; the Fresnel effect to model the amount of reflection and refraction at a fluid body's material boundary,\footnotecite[extras={, p.~404.}][opengl_yellow_book] of chromatic aberation of ice,\footnote{{\it Ibid}, p.~409.} or a jet's exhaust; are all some of the many examples we can implement. All of these are typically written in a high performance shader language like GLSL that executes directly on the player's video card.

Truth be told most people on this planet have never even used a telephone, let alone a top of the line, liquid cooled, \$500 graphics card that has the muscle for any of the aforementioned. As William Gibson once remarked, \quotation{\it The future is already here, it’s just not evenly distributed yet.} But even if everyone had powerful graphics hardware, there is still no guarantee that two users with two different vendor's top of the line cards would both have the same feature set -- or even implement the ones they {\it do} share in ways that produce the {\it same} results. 

For these reasons we need to provide fallback shaders whenever reasonable. This is for those with less capable hardware or whenever we can expect hiccups on hardware that ought to be capable enough but may have driver issues. This way users who already know their hardware is weak and do not expect it to do what more powerful hardware can do can still get the most out of Avaneya. Meanwhile those who {\it do} have powerful hardware can be satisfied knowing that they are getting the most out of their expensive hardware.

But in aiming for flexibility, we must draw the line somewhere. We still require \index{system requirements+GPU}graphics hardware that at least supports a programmable shader interface. Investing time in appeasing a dead fixed function pipeline is not a useful expenditure of resources in an era where even the cheapest and most primitive graphics hardware typically supports at least {\it some} minimal of a programmable shader interface.

\StartSubSection{Instrumentation & Performance Analysis}

A good engineering principle is to make something work first, then to make it work better. There will come a time when the engine is mature enough that introspection will be necessary to identify performance bottlenecks that were difficult to anticipate during the architectural design. One approach is to use instrumentation software like GNU's {\tt gprof} to examine call graphs.

On Intel architectures we should monitor the machine's performance counters\footnotecite[extras={, p. A--13}][intel_optimization_manual] for the frequency of cache misses. This is especially important on consoles, should we port Avaneya later.\footnotecite[extras={, p.~568.}][game_engine_architecture]

\StartSubSection{Lighting Models}

For lighting we will experiment with the capabilities of Ogre3D, our rendering engine. Still, there are some algorithms to consider earmarking for the time being. For static objects like buildings and terrain, we may be able to take advantage of spherical harmonics for real--time lighting.\footnotecite[extras={, p.~365.}][opengl_yellow_book] We can also consider using deferred shading for volume shadows.\footnote{{\it Ibid}, p.~392.} For global or ambient illumination we could use a hemispherical lighting model. Experimentation will be critical.

\StartSubSection{Memoization}

Memoization, not to be confused with memorization, is a technique in algorithm design that preserves the results of costly calculations whenever it is possible to re--use them without having to perform the same calculation again. When scripting we can take use Lua's built--in {\tt memoization(f)} function whenever possible.\footnotecite[extras={, p.~26.}][lua_programming_gems] The function works by creating a new function that returns the same result as {\tt f} on a given input, but by memoizing the result. As long as {\tt f} does not have any side effects, we can use the memoized variant with constant time performance.

\StartSubSection{Path Finding}

A path finding algorithm is necessary for vehicles and pedestrians. Sometimes units need to autonomously self--navigate from one location to another. Sometimes their movement could involve a non--trivial solution. By non--trivial, we mean the optimal path could involve balancing a number of different constraints like minimizing fuel expenditure, time, distance, and severity of the terrain.
\crlf

\placefigure
    [force,here]
    [figure:A_Star_Simple]
    {Our A\high{*} pathfinder algorithm with a simple test case.}
    {\externalfigure[Engineer_Contributors/Images/PathFinder_Simple.png][][width=.8\textwidth]}

For this problem we have selected the tried and true A\high{*} search strategy algorithm.\footnotecite[computational_intelligence] Our implementation is described in \in{section}[Artificial Intelligence].

\placefigure
    [force,here]
    [figure:A_Star_Complex]
    {Our A\high{*} pathfinder algorithm with a more complex test case.}
    {\externalfigure[Engineer_Contributors/Images/PathFinder_Complex.png][][width=.8\textwidth]}

\StartSubSection{Procedural Terrain}
Terrain problems are common to any game that requires the rendering of three--dimensional landscapes. Consider some other approaches.

What about height maps? Not if we need overhangs. If you have an underground vacuum tunnel carrying a train you cannot use them.

What about high resolution detail that we could provide manually. Perhaps pre--modelled in something like Blender with the help of some Perlin noise? Could that work for any reasonable level of magnification? That would probably be fine for offline rendering, but not if we wanted to maintain an interactive frame rate which is non--negotiable for a game. But users would probably be better satisfied with a virtual landscape that was influenced by the real thing if it were possible.

What about using real topographical data of Mars? Possible, but there is a problem. The best source of topographical data at the time of writing is the {\it Mars Orbiter Laser Altimeter (MOLA)} data set.\footnotecite[mola] MOLA was one of the instruments carried by the {\it Mars Global Surveyor}\index{Mars Global Surveyor} orbital spacecraft between the years of 1999 to 2001. Unfortunately the spatial resolution is inadequate for our purposes. For every degree of longitude at the planet's equator, there are 128 pixels of sampling available from the cylindrical projection\index{Cylindrical projection} data set. That might seem like a lot, but this is really only about half a kilometre per pixel. Consider for a moment just how much detail a player's booming Martian metropolis might pack in less than half a square kilometre.

If the user zoomed out to see an entire city, that might be fine, but what about if they zoomed in really close to the landscape to interact with various objects? Even if the data's spatial resolution was fine enough to provide for elevation details at distances as small as a metre, we are now left with a problem we already encountered had we gone with the Blender route -- too much geometry for the machine to realistically handle at an interactive frame rate. Whatever was viewable at a micro--level, even if we hide all of the landscape that is not visible, all of the details present in what is {\it still} present in the camera's viewport will bog the machine down. But perhaps there is another approach to consider.

Ryan Geiss\index{Geiss, Ryan} is well known for his Geiss visualizer for the Winamp media player\index{Winamp media player}. This non--free plugin is considered a classic. Ryan was a pioneer in the field of sound activated graphics (visualization) at the time, but he has also made contributions few have heard about in other fields like procedural terrain generation. His article on {\it Generating Complex Procedural Terrains Using the GPU}\footnotecite[geiss_fractal_terrain] provides a solution worth considering.

The method allows overhangs. It also generates rich and highly detailed geometry at {\it infinite} spatial resolutions while maintaining an interactive frame rate by generating the geometry entirely on the fly. This is accomplished by offloading the entire computation to the GPU where he relies on fractals and several octaves of noise to produce the vertex data. Consider taking a look at one of his demonstrations.\footnotecite[geiss_fractal_terrain_demo]

We are still left to solve other problems like terrain deformation and the community's desire to see real topographical data incorporated if possible. In the latter case it may be theoretically possible to influence Ryan's algorithm at a macro--level by \quotation{seeding it} with an initial brute--force approach using what is topographically known now while dynamically \quotation{filling in} the details algorithmically on the fly at runtime. We will have to experiment and adapt his algorithm as necessary. It may be possible to adapt protein--structure modelling and reconstruction algorithms from the realms of structural biology and bioinformatics for this purpose.

We will probably see a performance improvement in the terrain shaders when relying on hardware based GLSL implementations of the {\tt noise*()} functions to provide fast high performance pseudo--random number generators. At the time of writing unfortunately no known hardware vendor implements these functions.\footnote{Mesa\index{Mesa} 8.0, a popular software based OpenGL renderer, notes in its {\tt src/glsl/lower_noise.cpp} that {\it "no hardware has a noise instruction"}.} This may be due to patent trolls. Instead these function stubs return {\tt 0.0}. We will have to check at runtime whether available and if unavailable rely on another method like noise textures.\footnotecite[extras={, pp.~264--269.}][using_noise_in_shaders]

\StartSubSection{Random Number Generators}
Random numbers are vital to games. These numbers usually do not need to be as high quality as required in statistical and scientific computing, but at least better than what is implemented in most standard language APIs, such as C++. Case in point, few serious game developers actually rely on their C++ compiler's {\tt std::rand()} function.

The game can query the random number generator many thousands of times per second in some cases, with each number potentially contributing in a significant way to a sequence or causal chain of events. One number might determine the severity of a seasonal dust storm. A seasonal dust storm that in turn leads to a reduction of inbound starport flights. In turn this leads to a reduction in immigration.

We selected Makoto Matsumoto's algorithm,\footnotecite[mersenne_twister] a popular high quality pseudo--random number generator. The algorithm offers an excellent balance between performance and quality of output within a very large period.

As one of its many novel uses we could parametrically define some characteristics of a building where it does not need to respond directly to the state of the underlying simulation. Some aspects of its appearance and behaviour could rely on some element of randomness. Two identical pressurized habitat building units could incorporate random parameters to make the foliage in their courtyards different from one another by seeding a foliage generation subroutine with different values. But we need not stop at just geometry. We could use random parameters to generate a colour palette too. The possibilities are limited only by our creativity.

\StartSubSection{Square Roots}
Square roots are common in game programming and nearly always pop up whenever vectors, trigonometry, linear algebra and the like are involved. We avoid them whenever possible. We use the squared magnitude instead. The former is slow and the latter faster -- albeit at the cost of accuracy.

\StartSubSection{Vectorization}
Take advantage of the vectorization a given architecture's accelerated instruction set comes with. This is sometimes called single instruction, multiple data (SIMD). These days virtually every major architecture offers some variant of this concept under a name of its own. It works by taking a group of inputs and batch processes them simultaneously instead of serially. Calculating an otherwise costly normalization of a list of half a dozen double precision floating point vectors can be done this way with a single SIMD instruction.

Since we are using the GNU Compiler Collection we can use an already existing implementation of Intel's specification whenever working with {\tt amd64} or {\tt i686} architectures.\footnote{See the {\tt xmmintrin.h} header which ships with the GNU Compiler Collection.} This is useful for linear algebra and other math--related routines found in games. Better yet, we might instead rely on an architecturally agnostic approach by using GCC's built--in vector extensions.\footnotecite[gcc_vector_extensions]

